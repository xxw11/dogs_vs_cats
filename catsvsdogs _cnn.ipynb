{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './dogs-vs-cats/train'\n",
    "test_dir = './dogs-vs-cats/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "train_list = glob.glob(os.path.join(train_dir,'*.jpg'))\n",
    "test_list = glob.glob(os.path.join(test_dir, '*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_list, val_list = train_test_split(train_list, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms =  transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose([   \n",
    "    transforms.Resize((224, 224)),\n",
    "     transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,file_list,transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        self.filelength = len(self.file_list)\n",
    "        return self.filelength\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img_transformed = self.transform(img)\n",
    "        \n",
    "        label = img_path.split('/')[-1].split('.')[0].split('\\\\')[-1]\n",
    "        if label == \"dog\":\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        \n",
    "        return img_transformed,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset(train_list, transform=train_transforms)\n",
    "test_data = dataset(test_list, transform=test_transforms)\n",
    "val_data = dataset(val_list, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epoch = 10\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=batch_size, shuffle=True )\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3,10,kernel_size = 5)\n",
    "        self.conv2 = torch.nn.Conv2d(10,20,kernel_size = 5)\n",
    "        self.pooling = torch.nn.MaxPool2d(2)\n",
    "        self.fc1 = torch.nn.Linear(56180,1000)\n",
    "        self.fc2 = torch.nn.Linear(1000,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size = x.size(0)\n",
    "#         x为张量，张量.size 取出维度  取0  得到就是样本数量 n 3 224 224\n",
    "        x = x.view(batch_size,3,224,224)\n",
    "        x = self.pooling(F.relu(self.conv1(x)))\n",
    "        x = self.pooling(F.relu(self.conv2(x)))\n",
    "        x = x.view(batch_size,-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.01,momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx,data in enumerate(train_loader,0):\n",
    "        inputs,target = data\n",
    "#         inputs,target = inputs.to(device),target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "#         forward and backward and update\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 100 == 99:\n",
    "            print('[%d,%5d] loss: %.3f' % (epoch + 1,batch_idx + 1,running_loss / 100))\n",
    "            running_loss =0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "#         执行之后在下面代码就不会执行梯度\n",
    "        for data in val_loader:\n",
    "            images,labels = data\n",
    "#             images,labels = images.to(device),labels.to(device)\n",
    "#             拿数据\n",
    "            outputs = model(images)\n",
    "#             做预测，拿到的结果是一个矩阵，每一行都是一个独热向量\n",
    "            _, predicted = torch.max(outputs.data,dim = 1)\n",
    "#           返回 最大值 和 每一行的最大值下标\n",
    "#           指定沿着维度1（往下 行是第0个维度，向右 列是第一个维度）\n",
    "            total += labels.size(0)\n",
    "#             label是一个N 1元组 size 取 0 就是？\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy on test set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  100] loss: 0.693\n",
      "[3,  200] loss: 0.690\n"
     ]
    }
   ],
   "source": [
    "train_func(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_func():\n",
    "    dog_probs=[]\n",
    "    with torch.no_grad():\n",
    "        for data,fileid in test_loader:\n",
    "            preds = model(data)\n",
    "            preds_list = F.softmax(preds,dim=1)[:, 1].tolist()\n",
    "            dog_probs += list(zip(list(fileid),preds_list))\n",
    "    dog_probs.sort(key = lambda x : int(x[0]))\n",
    "    idx = list(map(lambda x: x[0],dog_probs))\n",
    "    prob = list(map(lambda x: x[1],dog_probs))\n",
    "    submission = pd.DataFrame({'id':int(idx),'label':prob})\n",
    "    submission.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  100] loss: 0.687\n",
      "[1,  200] loss: 0.685\n",
      "Accuracy on test set: 56 %\n",
      "[2,  100] loss: 0.681\n",
      "[2,  200] loss: 0.678\n",
      "Accuracy on test set: 57 %\n",
      "[3,  100] loss: 0.675\n",
      "[3,  200] loss: 0.668\n",
      "Accuracy on test set: 58 %\n",
      "[4,  100] loss: 0.667\n",
      "[4,  200] loss: 0.660\n",
      "Accuracy on test set: 60 %\n",
      "[5,  100] loss: 0.658\n",
      "[5,  200] loss: 0.655\n",
      "Accuracy on test set: 61 %\n",
      "[6,  100] loss: 0.647\n",
      "[6,  200] loss: 0.645\n",
      "Accuracy on test set: 63 %\n",
      "[7,  100] loss: 0.637\n",
      "[7,  200] loss: 0.633\n",
      "Accuracy on test set: 63 %\n",
      "[8,  100] loss: 0.631\n",
      "[8,  200] loss: 0.623\n",
      "Accuracy on test set: 64 %\n",
      "[9,  100] loss: 0.623\n",
      "[9,  200] loss: 0.610\n",
      "Accuracy on test set: 65 %\n",
      "[10,  100] loss: 0.609\n",
      "[10,  200] loss: 0.610\n",
      "Accuracy on test set: 66 %\n",
      "[11,  100] loss: 0.610\n",
      "[11,  200] loss: 0.612\n",
      "Accuracy on test set: 66 %\n",
      "[12,  100] loss: 0.601\n",
      "[12,  200] loss: 0.594\n",
      "Accuracy on test set: 67 %\n",
      "[13,  100] loss: 0.600\n",
      "[13,  200] loss: 0.595\n",
      "Accuracy on test set: 67 %\n",
      "[14,  100] loss: 0.595\n",
      "[14,  200] loss: 0.593\n",
      "Accuracy on test set: 68 %\n",
      "[15,  100] loss: 0.587\n",
      "[15,  200] loss: 0.591\n",
      "Accuracy on test set: 69 %\n",
      "[16,  100] loss: 0.586\n",
      "[16,  200] loss: 0.585\n",
      "Accuracy on test set: 69 %\n",
      "[17,  100] loss: 0.590\n",
      "[17,  200] loss: 0.587\n",
      "Accuracy on test set: 68 %\n",
      "[18,  100] loss: 0.581\n",
      "[18,  200] loss: 0.579\n",
      "Accuracy on test set: 70 %\n",
      "[19,  100] loss: 0.578\n",
      "[19,  200] loss: 0.570\n",
      "Accuracy on test set: 70 %\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    for epoch in range(19):\n",
    "        train_func(epoch)\n",
    "        test_func()\n",
    "    predict_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
